{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.25s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/591753] 正在读取captions并根据其分词建立词典...\n",
      "[100000/591753] 正在读取captions并根据其分词建立词典...\n",
      "[200000/591753] 正在读取captions并根据其分词建立词典...\n",
      "[300000/591753] 正在读取captions并根据其分词建立词典...\n",
      "[400000/591753] 正在读取captions并根据其分词建立词典...\n",
      "[500000/591753] 正在读取captions并根据其分词建立词典...\n",
      "初始化vocab.pkl文件成功\n",
      "loading annotations into memory...\n",
      "Done (t=1.19s)\n",
      "creating index...\n",
      "index created!\n",
      "正在对caption分词...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 591753/591753 [01:08<00:00, 8632.36it/s]\n",
      "D:\\python\\anaconda\\envs\\PyTorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\python\\anaconda\\envs\\PyTorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "D:\\python\\anaconda\\envs\\PyTorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "COCOAPIROOT = r\"D:\\学习资料\\实验室\"\n",
    "from pycocotools.coco import COCO\n",
    "from raw_program.data_loader import get_loader\n",
    "from raw_program.model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "# 选取合适参数\n",
    "batch_size = 128          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = False    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# 建立transforms\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# 建立dataloader\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file,\n",
    "                         cocoapi_loc=COCOAPIROOT)\n",
    "\n",
    "# 定义词典大小\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# 初始化encoder和decoder \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# 把模型移动到GPU中\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# 把可学习的参数建立一个列表\n",
    "params = list(encoder.embed.parameters()) + list(decoder.parameters())\n",
    "\n",
    "# 选定优化器\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# 设置每一个epoch训练多少步\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model save/load\n",
    "import os\n",
    "\n",
    "# Save\n",
    "torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-0.pkl'))\n",
    "torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-0.pkl'))\n",
    "# Load\n",
    "decoder_file = 'decoder-0.pkl'\n",
    "encoder_file = 'encoder-0.pkl'\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file),  map_location='cpu'))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file),  map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/4624], Loss: 3.6885, Perplexity: 39.98566\n",
      "Epoch [1/3], Step [200/4624], Loss: 3.4065, Perplexity: 30.16089\n",
      "Epoch [1/3], Step [300/4624], Loss: 3.9250, Perplexity: 50.6533\n",
      "Epoch [1/3], Step [400/4624], Loss: 3.0100, Perplexity: 20.2865\n",
      "Epoch [1/3], Step [500/4624], Loss: 3.0308, Perplexity: 20.7130\n",
      "Epoch [1/3], Step [600/4624], Loss: 3.0018, Perplexity: 20.1212\n",
      "Epoch [1/3], Step [700/4624], Loss: 2.8469, Perplexity: 17.2340\n",
      "Epoch [1/3], Step [800/4624], Loss: 2.7958, Perplexity: 16.3752\n",
      "Epoch [1/3], Step [900/4624], Loss: 2.6767, Perplexity: 14.5367\n",
      "Epoch [1/3], Step [1000/4624], Loss: 2.7064, Perplexity: 14.9753\n",
      "Epoch [1/3], Step [1100/4624], Loss: 2.5397, Perplexity: 12.6756\n",
      "Epoch [1/3], Step [1200/4624], Loss: 2.4240, Perplexity: 11.2910\n",
      "Epoch [1/3], Step [1300/4624], Loss: 2.4809, Perplexity: 11.9524\n",
      "Epoch [1/3], Step [1400/4624], Loss: 2.4782, Perplexity: 11.9195\n",
      "Epoch [1/3], Step [1500/4624], Loss: 2.5077, Perplexity: 12.2761\n",
      "Epoch [1/3], Step [1600/4624], Loss: 2.3695, Perplexity: 10.6916\n",
      "Epoch [1/3], Step [1700/4624], Loss: 2.4558, Perplexity: 11.6563\n",
      "Epoch [1/3], Step [1800/4624], Loss: 2.4324, Perplexity: 11.3867\n",
      "Epoch [1/3], Step [1900/4624], Loss: 2.7558, Perplexity: 15.7344\n",
      "Epoch [1/3], Step [2000/4624], Loss: 2.4189, Perplexity: 11.2335\n",
      "Epoch [1/3], Step [2100/4624], Loss: 2.3970, Perplexity: 10.9899\n",
      "Epoch [1/3], Step [2200/4624], Loss: 2.5138, Perplexity: 12.3517\n",
      "Epoch [1/3], Step [2300/4624], Loss: 2.1867, Perplexity: 8.90553\n",
      "Epoch [1/3], Step [2400/4624], Loss: 2.2866, Perplexity: 9.84125\n",
      "Epoch [1/3], Step [2500/4624], Loss: 2.3119, Perplexity: 10.0939\n",
      "Epoch [1/3], Step [2600/4624], Loss: 2.4269, Perplexity: 11.3233\n",
      "Epoch [1/3], Step [2700/4624], Loss: 2.4703, Perplexity: 11.8255\n",
      "Epoch [1/3], Step [2800/4624], Loss: 2.2868, Perplexity: 9.84336\n",
      "Epoch [1/3], Step [2900/4624], Loss: 2.1113, Perplexity: 8.25942\n",
      "Epoch [1/3], Step [3000/4624], Loss: 2.3687, Perplexity: 10.6839\n",
      "Epoch [1/3], Step [3100/4624], Loss: 2.1611, Perplexity: 8.68039\n",
      "Epoch [1/3], Step [3200/4624], Loss: 2.8594, Perplexity: 17.4513\n",
      "Epoch [1/3], Step [3300/4624], Loss: 2.3397, Perplexity: 10.3780\n",
      "Epoch [1/3], Step [3400/4624], Loss: 2.1257, Perplexity: 8.37842\n",
      "Epoch [1/3], Step [3500/4624], Loss: 2.1076, Perplexity: 8.22826\n",
      "Epoch [1/3], Step [3600/4624], Loss: 2.0254, Perplexity: 7.57895\n",
      "Epoch [1/3], Step [3700/4624], Loss: 2.4280, Perplexity: 11.3367\n",
      "Epoch [1/3], Step [3800/4624], Loss: 2.2319, Perplexity: 9.31770\n",
      "Epoch [1/3], Step [3900/4624], Loss: 2.0638, Perplexity: 7.87600\n",
      "Epoch [1/3], Step [4000/4624], Loss: 2.1879, Perplexity: 8.91687\n",
      "Epoch [1/3], Step [4100/4624], Loss: 2.1334, Perplexity: 8.44352\n",
      "Epoch [1/3], Step [4200/4624], Loss: 2.0362, Perplexity: 7.66143\n",
      "Epoch [1/3], Step [4300/4624], Loss: 2.4016, Perplexity: 11.0411\n",
      "Epoch [1/3], Step [4400/4624], Loss: 2.1994, Perplexity: 9.01985\n",
      "Epoch [1/3], Step [4500/4624], Loss: 2.1453, Perplexity: 8.54426\n",
      "Epoch [1/3], Step [4600/4624], Loss: 2.1549, Perplexity: 8.62741\n",
      "Epoch [2/3], Step [100/4624], Loss: 2.1426, Perplexity: 8.521883\n",
      "Epoch [2/3], Step [200/4624], Loss: 2.1512, Perplexity: 8.59500\n",
      "Epoch [2/3], Step [300/4624], Loss: 2.0770, Perplexity: 7.98053\n",
      "Epoch [2/3], Step [400/4624], Loss: 2.7377, Perplexity: 15.4521\n",
      "Epoch [2/3], Step [500/4624], Loss: 2.1391, Perplexity: 8.49224\n",
      "Epoch [2/3], Step [600/4624], Loss: 2.1011, Perplexity: 8.17541\n",
      "Epoch [2/3], Step [700/4624], Loss: 2.1260, Perplexity: 8.38152\n",
      "Epoch [2/3], Step [800/4624], Loss: 2.2238, Perplexity: 9.24244\n",
      "Epoch [2/3], Step [900/4624], Loss: 2.1326, Perplexity: 8.43647\n",
      "Epoch [2/3], Step [1000/4624], Loss: 2.1036, Perplexity: 8.1953\n",
      "Epoch [2/3], Step [1100/4624], Loss: 2.0574, Perplexity: 7.82565\n",
      "Epoch [2/3], Step [1200/4624], Loss: 2.0287, Perplexity: 7.60401\n",
      "Epoch [2/3], Step [1300/4624], Loss: 1.9070, Perplexity: 6.73306\n",
      "Epoch [2/3], Step [1400/4624], Loss: 1.9681, Perplexity: 7.15686\n",
      "Epoch [2/3], Step [1500/4624], Loss: 2.1393, Perplexity: 8.49380\n",
      "Epoch [2/3], Step [1600/4624], Loss: 1.9397, Perplexity: 6.95636\n",
      "Epoch [2/3], Step [1700/4624], Loss: 2.1491, Perplexity: 8.57732\n",
      "Epoch [2/3], Step [1800/4624], Loss: 2.0299, Perplexity: 7.61326\n",
      "Epoch [2/3], Step [1900/4624], Loss: 1.9847, Perplexity: 7.27689\n",
      "Epoch [2/3], Step [2000/4624], Loss: 2.1366, Perplexity: 8.47106\n",
      "Epoch [2/3], Step [2100/4624], Loss: 2.1074, Perplexity: 8.22711\n",
      "Epoch [2/3], Step [2200/4624], Loss: 2.0906, Perplexity: 8.08962\n",
      "Epoch [2/3], Step [2300/4624], Loss: 2.1689, Perplexity: 8.74835\n",
      "Epoch [2/3], Step [2400/4624], Loss: 2.1123, Perplexity: 8.26719\n",
      "Epoch [2/3], Step [2500/4624], Loss: 1.9878, Perplexity: 7.29961\n",
      "Epoch [2/3], Step [2600/4624], Loss: 2.0020, Perplexity: 7.40407\n",
      "Epoch [2/3], Step [2700/4624], Loss: 1.9509, Perplexity: 7.03489\n",
      "Epoch [2/3], Step [2800/4624], Loss: 2.1761, Perplexity: 8.81172\n",
      "Epoch [2/3], Step [2900/4624], Loss: 2.0769, Perplexity: 7.97990\n",
      "Epoch [2/3], Step [3000/4624], Loss: 1.8267, Perplexity: 6.21323\n",
      "Epoch [2/3], Step [3100/4624], Loss: 2.1097, Perplexity: 8.24594\n",
      "Epoch [2/3], Step [3200/4624], Loss: 2.0299, Perplexity: 7.61342\n",
      "Epoch [2/3], Step [3300/4624], Loss: 2.0879, Perplexity: 8.06796\n",
      "Epoch [2/3], Step [3400/4624], Loss: 2.0424, Perplexity: 7.70910\n",
      "Epoch [2/3], Step [3500/4624], Loss: 1.9218, Perplexity: 6.83292\n",
      "Epoch [2/3], Step [3600/4624], Loss: 2.1173, Perplexity: 8.30877\n",
      "Epoch [2/3], Step [3700/4624], Loss: 1.9417, Perplexity: 6.97043\n",
      "Epoch [2/3], Step [3800/4624], Loss: 2.0801, Perplexity: 8.00514\n",
      "Epoch [2/3], Step [3900/4624], Loss: 2.1005, Perplexity: 8.17025\n",
      "Epoch [2/3], Step [4000/4624], Loss: 1.8552, Perplexity: 6.39283\n",
      "Epoch [2/3], Step [4100/4624], Loss: 2.0377, Perplexity: 7.67265\n",
      "Epoch [2/3], Step [4200/4624], Loss: 2.6639, Perplexity: 14.3528\n",
      "Epoch [2/3], Step [4300/4624], Loss: 1.8952, Perplexity: 6.65399\n",
      "Epoch [2/3], Step [4400/4624], Loss: 2.5232, Perplexity: 12.4685\n",
      "Epoch [2/3], Step [4500/4624], Loss: 1.9066, Perplexity: 6.73000\n",
      "Epoch [2/3], Step [4600/4624], Loss: 2.0566, Perplexity: 7.81961\n",
      "Epoch [3/3], Step [100/4624], Loss: 1.9418, Perplexity: 6.9710815\n",
      "Epoch [3/3], Step [200/4624], Loss: 1.9345, Perplexity: 6.92021\n",
      "Epoch [3/3], Step [300/4624], Loss: 1.9474, Perplexity: 7.01042\n",
      "Epoch [3/3], Step [400/4624], Loss: 1.9653, Perplexity: 7.13680\n",
      "Epoch [3/3], Step [500/4624], Loss: 2.4239, Perplexity: 11.2896\n",
      "Epoch [3/3], Step [600/4624], Loss: 1.9924, Perplexity: 7.33346\n",
      "Epoch [3/3], Step [700/4624], Loss: 1.9011, Perplexity: 6.69359\n",
      "Epoch [3/3], Step [800/4624], Loss: 1.9382, Perplexity: 6.94659\n",
      "Epoch [3/3], Step [900/4624], Loss: 1.8512, Perplexity: 6.36756\n",
      "Epoch [3/3], Step [1000/4624], Loss: 2.0530, Perplexity: 7.7916\n",
      "Epoch [3/3], Step [1100/4624], Loss: 2.0169, Perplexity: 7.51532\n",
      "Epoch [3/3], Step [1200/4624], Loss: 1.9433, Perplexity: 6.98186\n",
      "Epoch [3/3], Step [1300/4624], Loss: 1.9099, Perplexity: 6.75241\n",
      "Epoch [3/3], Step [1400/4624], Loss: 1.9715, Perplexity: 7.18158\n",
      "Epoch [3/3], Step [1500/4624], Loss: 1.9652, Perplexity: 7.13650\n",
      "Epoch [3/3], Step [1600/4624], Loss: 1.9320, Perplexity: 6.90367\n",
      "Epoch [3/3], Step [1700/4624], Loss: 1.9068, Perplexity: 6.73189\n",
      "Epoch [3/3], Step [1800/4624], Loss: 1.9208, Perplexity: 6.82612\n",
      "Epoch [3/3], Step [1900/4624], Loss: 1.9861, Perplexity: 7.28721\n",
      "Epoch [3/3], Step [2000/4624], Loss: 2.0784, Perplexity: 7.99169\n",
      "Epoch [3/3], Step [2100/4624], Loss: 2.0352, Perplexity: 7.65403\n",
      "Epoch [3/3], Step [2200/4624], Loss: 2.9530, Perplexity: 19.1639\n",
      "Epoch [3/3], Step [2300/4624], Loss: 1.9081, Perplexity: 6.74000\n",
      "Epoch [3/3], Step [2400/4624], Loss: 2.0714, Perplexity: 7.93585\n",
      "Epoch [3/3], Step [2500/4624], Loss: 2.0196, Perplexity: 7.53542\n",
      "Epoch [3/3], Step [2600/4624], Loss: 1.9584, Perplexity: 7.08805\n",
      "Epoch [3/3], Step [2700/4624], Loss: 1.9759, Perplexity: 7.21309\n",
      "Epoch [3/3], Step [2800/4624], Loss: 2.0230, Perplexity: 7.56080\n",
      "Epoch [3/3], Step [2900/4624], Loss: 1.9536, Perplexity: 7.05401\n",
      "Epoch [3/3], Step [3000/4624], Loss: 2.0340, Perplexity: 7.64446\n",
      "Epoch [3/3], Step [3100/4624], Loss: 2.0415, Perplexity: 7.70181\n",
      "Epoch [3/3], Step [3200/4624], Loss: 1.7924, Perplexity: 6.00419\n",
      "Epoch [3/3], Step [3300/4624], Loss: 2.4417, Perplexity: 11.4929\n",
      "Epoch [3/3], Step [3400/4624], Loss: 1.9670, Perplexity: 7.14947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Step [3500/4624], Loss: 1.9405, Perplexity: 6.96227\n",
      "Epoch [3/3], Step [3600/4624], Loss: 2.0742, Perplexity: 7.95798\n",
      "Epoch [3/3], Step [3700/4624], Loss: 1.9367, Perplexity: 6.93571\n",
      "Epoch [3/3], Step [3800/4624], Loss: 1.8853, Perplexity: 6.58820\n",
      "Epoch [3/3], Step [3900/4624], Loss: 1.8539, Perplexity: 6.38444\n",
      "Epoch [3/3], Step [4000/4624], Loss: 1.9714, Perplexity: 7.18109\n",
      "Epoch [3/3], Step [4100/4624], Loss: 1.9455, Perplexity: 6.99726\n",
      "Epoch [3/3], Step [4200/4624], Loss: 1.8973, Perplexity: 6.66810\n",
      "Epoch [3/3], Step [4300/4624], Loss: 1.9660, Perplexity: 7.14173\n",
      "Epoch [3/3], Step [4400/4624], Loss: 1.9410, Perplexity: 6.96560\n",
      "Epoch [3/3], Step [4500/4624], Loss: 1.9476, Perplexity: 7.01180\n",
      "Epoch [3/3], Step [4600/4624], Loss: 2.0703, Perplexity: 7.92712\n",
      "Epoch [3/3], Step [4624/4624], Loss: 1.9401, Perplexity: 6.95954本次训练时长：137305.35981154442\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "# Select True if training on local desktop. False to train on GPU workspace\n",
    "local = False\n",
    "# if not local:\n",
    "start_time = time.time()\n",
    "#     response = requests.request(\"GET\", \n",
    "#                                 \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "#                                 headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for i_step in range(1, total_step+1):\n",
    "#         if not local:\n",
    "#             if time.time() - old_time > 60:\n",
    "#                 old_time = time.time()\n",
    "#                 requests.request(\"POST\", \n",
    "#                                  \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "#                                  headers={'Authorization': \"STAR \" + response.text})\n",
    "\n",
    "        # 随机从caption_length中采样返回对应索引\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # 创建一个样本\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        # 获取这批数据\n",
    "        images, captions = next(iter(data_loader))\n",
    "        # 将数据移到GPU中\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        # 将梯度归零\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        # 将输入传到encoder和decoder中\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新优化器参数\n",
    "        optimizer.step()\n",
    "        # 获取训练的统计数据\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        # 打印训练数据(同一行中)\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        # 将数据存到文件中\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        # 打印训练数据(换行)\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "\n",
    "    # 保存权重\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# 关闭log文件\n",
    "f.close()\n",
    "end_time = time.time()\n",
    "print(\"本次训练时长：{}\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
